{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheenms/GoogleCoLab/blob/main/nlp_tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ba5cHmgjpn7",
        "outputId": "b94307ab-1648-4ca6-b1d1-190330b7f6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,214 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,472 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,267 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,132 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,040 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,226 kB]\n",
            "Fetched 12.6 MB in 9s (1,378 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.2.2'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fo8HPyraKKhR"
      },
      "outputs": [],
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NLPTokens\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XyUv4abqjkof"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer # it breaks the array into smaller pieces\n",
        "from pyspark.sql.functions import col, udf #user defined functions . \n",
        "from pyspark.sql.types import IntegerType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QHYBC46Xjkom"
      },
      "outputs": [],
      "source": [
        "# Create sample DataFrame\n",
        "dataframe = spark.createDataFrame([\n",
        "    (0, \"Spark is great\"),\n",
        "    (1, \"We are learning Spark\"),\n",
        "    (2, \"Spark is better than hadoop no doubt\")\n",
        "], [\"id\", \"sentence\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqpXq9MQjkoq",
        "outputId": "1dbb8a27-c6e6-4872-fc1f-3055ae5ef686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------------------------+\n",
            "|id |sentence                            |\n",
            "+---+------------------------------------+\n",
            "|0  |Spark is great                      |\n",
            "|1  |We are learning Spark               |\n",
            "|2  |Spark is better than hadoop no doubt|\n",
            "+---+------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show DataFrame\n",
        "dataframe.show(truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7wJU0_Cjkow",
        "outputId": "861e60ff-b827-4cb8-df42-3ba8d3a7e2cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer_2c96f9317eb5"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Tokenize word\n",
        "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHYnBPMqjko0",
        "outputId": "8359236f-6929-4805-907c-3a28e5030e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|            sentence|\n",
            "+---+--------------------+\n",
            "|  0|      Spark is great|\n",
            "|  1|We are learning S...|\n",
            "|  2|Spark is better t...|\n",
            "+---+--------------------+\n",
            "\n",
            "+---+------------------------------------+--------------------------------------------+\n",
            "|id |sentence                            |words                                       |\n",
            "+---+------------------------------------+--------------------------------------------+\n",
            "|0  |Spark is great                      |[spark, is, great]                          |\n",
            "|1  |We are learning Spark               |[we, are, learning, spark]                  |\n",
            "|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n",
            "+---+------------------------------------+--------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show DataFrame\n",
        "dataframe.show()\n",
        "# Transform and show DataFrame\n",
        "tokenized = tokenizer.transform(dataframe)\n",
        "tokenized.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function will return the length of a list of words\n",
        "def wordListLength(wordList):\n",
        "  return len(wordList)"
      ],
      "metadata": {
        "id": "EeA5vrlgMQ1U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call the udf function on the words column in the dataframe\n",
        "\n",
        " # udf takes 2 parameters -\n",
        " # input function, return data type of the function\n",
        " \n",
        "tokenCounter = udf(wordListLength, IntegerType())"
      ],
      "metadata": {
        "id": "tLUhyJt7MeYK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k92zPWKjkGzp",
        "outputId": "4e9c345c-b868-41d6-c151-d90131ab2e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------------------------+--------------------------------------------+----------+\n",
            "|id |sentence                            |words                                       |word count|\n",
            "+---+------------------------------------+--------------------------------------------+----------+\n",
            "|0  |Spark is great                      |[spark, is, great]                          |3         |\n",
            "|1  |We are learning Spark               |[we, are, learning, spark]                  |4         |\n",
            "|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7         |\n",
            "+---+------------------------------------+--------------------------------------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# apply the udf function\n",
        "tokenized = tokenized.withColumn(\"word count\", tokenCounter(col(\"words\")))\n",
        "\n",
        "tokenized.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function that will count the number of vowels\n",
        "def vowelCounter(wordList):\n",
        "  # set up a total\n",
        "  count = 0\n",
        "\n",
        "  # use a loop to check for vowels\n",
        "  for word in wordList:\n",
        "    # for each word in the word array, do the following:\n",
        "    # loop through each letter in the word\n",
        "    for letter in word:\n",
        "      # for each letter in each word, do the following:\n",
        "      # check to see if the letter is a vowel - a, e, i, o, u\n",
        "      if letter in ('a', 'e', 'i', 'o', 'u'):\n",
        "        # add 1 to the count\n",
        "        count += 1\n",
        "\n",
        "  # once the loop finishes, return the count (integer)\n",
        "  return count\n"
      ],
      "metadata": {
        "id": "Dk1JuMZwNpdC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vowelCounter = udf(vowelCounter, IntegerType())\n",
        "\n",
        "tokenized = tokenized.withColumn(\"vowel count\", vowelCounter(col(\"words\")))\n",
        "\n",
        "tokenized.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyuNkKrIP2zV",
        "outputId": "184a7561-e77a-4183-9ff4-15d58cc06584"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------------------------+--------------------------------------------+----------+-----------+\n",
            "|id |sentence                            |words                                       |word count|vowel count|\n",
            "+---+------------------------------------+--------------------------------------------+----------+-----------+\n",
            "|0  |Spark is great                      |[spark, is, great]                          |3         |4          |\n",
            "|1  |We are learning Spark               |[we, are, learning, spark]                  |4         |7          |\n",
            "|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7         |11         |\n",
            "+---+------------------------------------+--------------------------------------------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}