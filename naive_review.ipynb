{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheenms/GoogleCoLab/blob/main/naive_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUVgL1wNNajZ",
        "outputId": "928167ae-e4ae-460b-db1f-6a5fe17f0721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\r                                                                               \rGet:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 17.1 kB/88.7 k\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 20.0 kB/88.7 k\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 20.0 kB/88.7 k\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [98.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,216 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [992 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,133 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,554 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,226 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,040 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,472 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,267 kB]\n",
            "Fetched 17.6 MB in 7s (2,389 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.2.2'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KI-XYRwhCS6s"
      },
      "outputs": [],
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnI0zdY5NYCJ",
        "outputId": "4e78a93b-2f19-4a7d-efae-25bbce245bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "|class   |text                                                                                                           |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "|positive|Wow... Loved this place.                                                                                       |\n",
            "|negative|Crust is not good.                                                                                             |\n",
            "|negative|Not tasty and the texture was just nasty.                                                                      |\n",
            "|positive|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |\n",
            "|positive|The selection on the menu was great and so were the prices.                                                    |\n",
            "|negative|Now I am getting angry and I want my damn pho.                                                                 |\n",
            "|negative|Honeslty it didn't taste THAT fresh.)                                                                          |\n",
            "|negative|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|\n",
            "|positive|The fries were great too.                                                                                      |\n",
            "|positive|A great touch.                                                                                                 |\n",
            "|positive|Service was very prompt.                                                                                       |\n",
            "|negative|Would not go back.                                                                                             |\n",
            "|negative|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |\n",
            "|positive|I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!                                                    |\n",
            "|negative|I was disgusted because I was pretty sure that was human hair.                                                 |\n",
            "|negative|I was shocked because no signs indicate cash only.                                                             |\n",
            "|positive|Highly recommended.                                                                                            |\n",
            "|negative|Waitress was a little slow in service.                                                                         |\n",
            "|negative|This place is not worth your time, let alone Vegas.                                                            |\n",
            "|negative|did not like at all.                                                                                           |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/22-big-data/day_2/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show(truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BbzYExyNYCR",
        "outputId": "0dad7ad7-6983-44b6-e355-57f4b2a31b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------------------------------------------------------------------------------------------------------+------+\n",
            "|class   |text                                                                                                           |length|\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+------+\n",
            "|positive|Wow... Loved this place.                                                                                       |24    |\n",
            "|negative|Crust is not good.                                                                                             |18    |\n",
            "|negative|Not tasty and the texture was just nasty.                                                                      |41    |\n",
            "|positive|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |87    |\n",
            "|positive|The selection on the menu was great and so were the prices.                                                    |59    |\n",
            "|negative|Now I am getting angry and I want my damn pho.                                                                 |46    |\n",
            "|negative|Honeslty it didn't taste THAT fresh.)                                                                          |37    |\n",
            "|negative|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|111   |\n",
            "|positive|The fries were great too.                                                                                      |25    |\n",
            "|positive|A great touch.                                                                                                 |14    |\n",
            "|positive|Service was very prompt.                                                                                       |24    |\n",
            "|negative|Would not go back.                                                                                             |18    |\n",
            "|negative|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |99    |\n",
            "|positive|I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!                                                    |59    |\n",
            "|negative|I was disgusted because I was pretty sure that was human hair.                                                 |62    |\n",
            "|negative|I was shocked because no signs indicate cash only.                                                             |50    |\n",
            "|positive|Highly recommended.                                                                                            |19    |\n",
            "|negative|Waitress was a little slow in service.                                                                         |38    |\n",
            "|negative|This place is not worth your time, let alone Vegas.                                                            |51    |\n",
            "|negative|did not like at all.                                                                                           |20    |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show(truncate = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od7Qj0sxNYCW"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "59dwxefsNYCX"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yssO0_Q5NYCb"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "E_YyUpR3NYCf"
      },
      "outputs": [],
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qBViHQOaNYCj"
      },
      "outputs": [],
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDODyxF7NYCn",
        "outputId": "66af055a-3f62-4446-a7e0-d696279e2ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|label|features                                                                                                                                                                                                                                                                     |\n",
            "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1.0  |(262145,[177414,216221,239331,262144],[6.215607598755275,4.51085950651685,3.8642323415917974,24.0])                                                                                                                                                                          |\n",
            "|0.0  |(262145,[49815,237498,262144],[3.7732605633860707,5.810142490647111,18.0])                                                                                                                                                                                                   |\n",
            "|0.0  |(262145,[109649,155665,223782,262144],[6.215607598755275,5.52246041819533,4.962844630259907,41.0])                                                                                                                                                                           |\n",
            "|1.0  |(262145,[53101,68727,91192,143501,146390,201874,216221,243871,248687,253047,262144],[6.215607598755275,6.215607598755275,5.116995310087166,4.075541435259004,6.215607598755275,5.810142490647111,4.51085950651685,6.215607598755275,6.215607598755275,5.52246041819533,87.0])|\n",
            "|1.0  |(262145,[15370,77733,151571,261870,262144],[4.829313237635384,5.52246041819533,4.6061696863211745,2.9197707327509463,59.0])                                                                                                                                                  |\n",
            "|0.0  |(262145,[98142,131537,190256,230764,255299,262144],[5.29931686688112,6.215607598755275,4.269697449699962,4.829313237635384,5.810142490647111,46.0])                                                                                                                          |\n",
            "|0.0  |(262145,[59172,221770,228557,262144],[6.215607598755275,4.711530201979001,6.215607598755275,37.0])                                                                                                                                                                           |\n",
            "|0.0  |(262145,[63420,85530,89720,121517,140784,159927,198468,208258,231798,262144],[6.215607598755275,4.962844630259907,5.810142490647111,3.3252358408591105,4.13616605707544,5.116995310087166,6.215607598755275,3.147554663621658,6.215607598755275,111.0])                      |\n",
            "|1.0  |(262145,[53777,171611,261870,262144],[5.29931686688112,4.829313237635384,2.9197707327509463,25.0])                                                                                                                                                                           |\n",
            "|1.0  |(262145,[221827,261870,262144],[6.215607598755275,2.9197707327509463,14.0])                                                                                                                                                                                                  |\n",
            "|1.0  |(262145,[43756,227670,262144],[2.883403088580071,6.215607598755275,24.0])                                                                                                                                                                                                    |\n",
            "|0.0  |(262145,[127310,148675,262144],[3.96431580014878,3.195182712610913,18.0])                                                                                                                                                                                                    |\n",
            "|0.0  |(262145,[407,31536,109230,171222,176797,185123,191174,203802,262144],[5.810142490647111,4.4238481295272205,5.810142490647111,4.343805421853684,5.810142490647111,6.215607598755275,5.810142490647111,3.730700948967275,99.0])                                                |\n",
            "|1.0  |(262145,[18098,93838,111292,148426,204491,210058,262144],[6.215607598755275,4.829313237635384,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275,59.0])                                                                                                 |\n",
            "|0.0  |(262145,[23071,129900,134125,134303,248803,262144],[3.96431580014878,6.215607598755275,4.829313237635384,5.810142490647111,6.215607598755275,62.0])                                                                                                                          |\n",
            "|0.0  |(262145,[129941,159775,168139,182011,187580,262144],[6.215607598755275,6.215607598755275,5.810142490647111,6.215607598755275,6.215607598755275,50.0])                                                                                                                        |\n",
            "|1.0  |(262145,[19633,215473,262144],[5.29931686688112,6.215607598755275,19.0])                                                                                                                                                                                                     |\n",
            "|0.0  |(262145,[27707,65069,147752,242022,262144],[4.962844630259907,4.075541435259004,4.711530201979001,4.51085950651685,38.0])                                                                                                                                                    |\n",
            "|0.0  |(262145,[20891,27308,51247,70998,138954,173339,262144],[4.711530201979001,6.215607598755275,4.51085950651685,2.5780214390288894,6.215607598755275,5.810142490647111,51.0])                                                                                                   |\n",
            "|0.0  |(262145,[8287,208258,262144],[5.810142490647111,3.147554663621658,20.0])                                                                                                                                                                                                     |\n",
            "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show(truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WzfCQmrVNYCr"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeckHhg5NYCv",
        "outputId": "38edc128-8067-406f-de21-8b7d79929a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|negative|\"It was extremely...|    51|  0.0|[\"it, was, extrem...|[\"it, extremely, ...|(262144,[23071,75...|(262144,[23071,75...|(262145,[23071,75...|[-460.69503949090...|[0.99999558250561...|       0.0|\n",
            "|negative|\"The descriptions...|    71|  0.0|[\"the, descriptio...|[\"the, descriptio...|(262144,[7527,769...|(262144,[7527,769...|(262145,[7527,769...|[-858.93918802079...|[0.99999999999987...|       0.0|\n",
            "|negative|\"the food is not ...|    80|  0.0|[\"the, food, is, ...|[\"the, food, tast...|(262144,[41509,45...|(262144,[41509,45...|(262145,[41509,45...|[-741.97497563927...|[0.99999999999606...|       0.0|\n",
            "|negative|              #NAME?|     6|  0.0|            [#name?]|            [#name?]|(262144,[197050],...|(262144,[197050],...|(262145,[197050,2...|[-73.575518084230...|[0.04800001064780...|       1.0|\n",
            "|negative|-Drinks took clos...|    58|  0.0|[-drinks, took, c...|[-drinks, took, c...|(262144,[6586,218...|(262144,[6586,218...|(262145,[6586,218...|[-589.60293369544...|[0.99999999999998...|       0.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVFrWcHINYCz",
        "outputId": "8b3e0f03-ba3f-4097-9c61-524462026592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.727455\n"
          ]
        }
      ],
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOpKc638NlCQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nteract": {
      "version": "0.11.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}